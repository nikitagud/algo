1. B-Tree (დროითი კომპლექსურობა და ძირითადი საკითხები)
რა არის B-Tree-ს დროითი კომპლექსურობა საძიებო ოპერაციისთვის?
O(log n), რადგან B-Tree დაბალანსებული სტრუქტურაა, რომლის სიმაღლეც ლოგარითმულად იზრდება.

როგორ მოქმედებს B-Tree-ს ორდენი (order) მის სიმაღლეზე?
უფრო მაღალი ორდენის (m) B-Tree უფრო დაბალი სიმაღლის იქნება, რადგან თითოეულ კვანძში მეტი გასაღები (key) იქნება.

როგორია B-Tree-ს ჩასმისა და წაშლის ოპერაციების დროითი ანალიზი?
O(log n), რადგან კვანძში გასაღების (key) ჩასმა ან წაშლა ხდება ლოგარითმული სიღრმის ძიებით.

რატომ გამოიყენება B-Tree მონაცემთა ბაზებში და ფაილურ სისტემებში?
ის ოპტიმიზირებულია დისკზე წვდომისთვის, რადგან B-Tree-ს დიდი შვილები (children) ჰყავს, რაც ამცირებს I/O ოპერაციებს.

რა ხდება, როცა B-Tree-ს კვანძი ივსება?
კვანძის გაყოფა (split) ხდება, სადაც შუა ელემენტი ადის ზემოთ, ხოლო მარცხენა და მარჯვენა ნაწილები ახალ შვილებად იფანტებიან.

2. Heap-ხის სტრუქტურა
რა განსხვავებაა Max-Heap-სა და Min-Heap-ს შორის?
Max-Heap – ფესვი (root) არის უდიდესი ელემენტი.
Min-Heap – ფესვი (root) არის უმცირესი ელემენტი.

როგორია insert და delete ოპერაციების დროითი სირთულე Heap-ში?
O(log n), რადგან ელემენტი შეიძლება უნდა ავწიოთ ან დავწიოთ ბალანსისთვის.

როგორია Heap-ის heapify() ფუნქციის მუშაობის დროითი სირთულე?
O(n), რადგან ბოლო შრეებიდან (leaves) დაწყებული heapify() იყენებს რეკურსიულ ოპტიმიზაციას.

როგორ გამოიყენება Heap პრიორიტეტული რიგების (priority queue) გასამართად?
Heap-ი ინარჩუნებს ყველაზე მაღალ პრიორიტეტულ ელემენტს ზედა დონეზე, რაც O(1) დროში იძლევა მაქსიმუმს/მინიმუმს.

რატომ არის Heap იდეალური სტრუქტურა Dijkstra-ს ალგორითმისთვის?
მინიმალური გზის არჩევა სწრაფია – ყოველ ციკლში ყველაზე მცირე წონის წვერი O(log n) დროში ამოვარდება Min-Heap-დან.

3. ჰეშ ცხრილები
კითხვები და პასუხები
როგორია ჰეშ ცხრილის ძირითადი ოპერაციების (insert, delete, search) დროითი კომპლექსურობა?
საშუალოდ O(1), მაგრამ ცუდი ჰეშ ფუნქციის ან კოლიზიების შემთხვევაში შეიძლება O(n) გახდეს.

რა არის კოლიზია (collision) და როგორ შეიძლება მისი მოგვარება?
კოლიზია ხდება, როცა ორი გასაღები (key) ერთსა და იმავე ჰეშ ინდექსზე ხვდება.
მოგვარების მეთოდები:

Chaining – კოლიზიის შემთხვევაში ელემენტები სიაში (linked list) ინახება.
Open Addressing – ახალი თავისუფალი ინდექსი ეძებება (მაგ. Linear Probing, Quadratic Probing).
რა განსხვავებაა chaining-სა და open addressing-ს შორის?

Chaining – ერთსა და იმავე bucket-ში არსებული ელემენტები კავშირიანი სიით (linked list) ინახება.
Open Addressing – ცხრილში თავისუფალი სლოტები გამოიყენება კოლიზიების მოსაგვარებლად.
როგორია ჰეშ ფუნქციის კარგი თვისებები?

სწრაფი გამოთვლა (O(1))
ერთგვაროვანი განაწილება (uniform distribution)
მინიმალური კოლიზიები
რა არის load factor და როგორ მოქმედებს ჰეშ ცხრილის მუშაობაზე?
Load Factor = (ელემენტების რაოდენობა) / (ცხრილის ზომა).
თუ Load Factor ძალიან დიდია (>0.7), საჭიროა ცხრილის გადიდება (rehashing), რათა შემცირდეს კოლიზიები.

class HashTable:
    def __init__(self, size):
        self.size = size
        self.table = [None] * size

    def hash_function(self, key):
        return hash(key) % self.size

    def insert(self, key, value):
        index = self.hash_function(key)
        if self.table[index] is None:
            self.table[index] = []
        self.table[index].append((key, value))

    def search(self, key):
        index = self.hash_function(key)
        if self.table[index] is not None:
            for k, v in self.table[index]:
                if k == key:
                    return v
        return None

    def delete(self, key):
        index = self.hash_function(key)
        if self.table[index] is not None:
            self.table[index] = [(k, v) for k, v in self.table[index] if k != key]

# მაგალითი
ht = HashTable(10)
ht.insert("name", "Alice")
ht.insert("age", 25)
print(ht.search("name"))  # Alice
ht.delete("name")
print(ht.search("name"))  # None


[Index] -> [(Key, Value)]
[0] -> []
[1] -> [("Alice", 25)]
[2] -> []
[3] -> [("Bob", 30)]
[4] -> []
...

